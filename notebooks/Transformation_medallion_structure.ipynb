{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99d7ec3d-9866-411d-a7c2-b09f0751e216",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Importing all the necessory libraries\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "spark = SparkSession.builder.appName(\"EcomDataPipeline\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "051f34bc-9d45-4fbe-8332-bd38a84c61a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/lz2 -> abfss://landing-zone-2@ecomadlsatul.dfs.core.windows.net\n/databricks-datasets -> databricks-datasets\n/Volumes -> UnityCatalogVolumes\n/mnt/ecomdata -> abfss://landing-zone-2@ecomadlsatul.dfs.core.windows.net\n/databricks/mlflow-tracking -> databricks/mlflow-tracking\n/databricks-results -> databricks-results\n/databricks/mlflow-registry -> databricks/mlflow-registry\n/Volume -> DbfsReserved\n/volumes -> DbfsReserved\n/ -> DatabricksRoot\n/volume -> DbfsReserved\nNothing to unmount or already gone: An error occurred while calling o462.unmount.\n: java.rmi.RemoteException: java.lang.IllegalArgumentException: requirement failed: Directory not mounted: /mnt/ecomdata1; nested exception is: \n\tjava.lang.IllegalArgumentException: requirement failed: Directory not mounted: /mnt/ecomdata1\n\tat com.databricks.backend.daemon.data.client.BaseDbfsClient.send0(BaseDbfsClient.scala:161)\n\tat com.databricks.backend.daemon.data.client.BaseDbfsClient.sendIdempotent(BaseDbfsClient.scala:69)\n\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.unmount(DBUtilsCore.scala:1661)\n\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.$anonfun$unmount$1(DBUtilsCore.scala:1677)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:510)\n\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionContext(DBUtilsCore.scala:89)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionTags(DBUtilsCore.scala:89)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperationWithResultTags(DBUtilsCore.scala:89)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:511)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperation(DBUtilsCore.scala:89)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.recordDbutilsFsOp(DBUtilsCore.scala:154)\n\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.unmount(DBUtilsCore.scala:1677)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)\n\tat py4j.Gateway.invoke(Gateway.java:306)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:197)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:117)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\nCaused by: java.lang.IllegalArgumentException: requirement failed: Directory not mounted: /mnt/ecomdata1\n\tat scala.Predef$.require(Predef.scala:281)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$deleteMount$1(MetadataManager.scala:977)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$modifyAndVerify$2(MetadataManager.scala:1259)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.withRetries(MetadataManager.scala:1032)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.modifyAndVerify(MetadataManager.scala:1248)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.deleteMount(MetadataManager.scala:981)\n\tat com.databricks.backend.daemon.data.server.handler.MountHandler.receive(MountHandler.scala:144)\n\tat com.databricks.backend.daemon.data.server.handler.DbfsRequestHandler.receive(DbfsRequestHandler.scala:16)\n\tat com.databricks.backend.daemon.data.server.handler.DbfsRequestHandler.receive$(DbfsRequestHandler.scala:15)\n\tat com.databricks.backend.daemon.data.server.handler.MountHandler.receive(MountHandler.scala:39)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1(SessionContext.scala:51)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1$adapted(SessionContext.scala:50)\n\tat scala.collection.immutable.List.foreach(List.scala:431)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.queryHandlers(SessionContext.scala:50)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend.$anonfun$handleOtherRpc$2(DbfsServerBackend.scala:630)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:299)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:295)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend.com$databricks$backend$daemon$data$server$DbfsServerBackend$$handleOtherRpc(DbfsServerBackend.scala:630)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$1.applyOrElse(DbfsServerBackend.scala:548)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$1.applyOrElse(DbfsServerBackend.scala:462)\n\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)\n\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)\n\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:510)\n\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:299)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:295)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)\n\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:511)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)\n\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)\n\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:988)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:908)\n\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$5(JettyServer.scala:548)\n\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$5$adapted(JettyServer.scala:513)\n\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$12(ActivityContextFactory.scala:914)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:299)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:295)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:58)\n\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$2(ActivityContextFactory.scala:914)\n\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:877)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:859)\n\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withServiceRequestActivity$26(ActivityContextFactory.scala:331)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:299)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:295)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:58)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:331)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:513)\n\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:408)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)\n\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)\n\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\n\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\n\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\n\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\n\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\n\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\n\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:111)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:299)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:295)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:46)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:111)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:132)\n\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:129)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:46)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:93)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n\tat java.lang.Thread.run(Thread.java:840)\n\n"
     ]
    }
   ],
   "source": [
    "# Checking for Mounting\n",
    "\n",
    "for m in dbutils.fs.mounts():\n",
    "    print(m.mountPoint, \"->\", m.source)\n",
    "\n",
    "try:\n",
    "    dbutils.fs.unmount(\"/mnt/ecomdata1\")\n",
    "    print(\"Unmounted /mnt/ecomdata1\")\n",
    "except Exception as e:\n",
    "    print(\"Nothing to unmount or already gone:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d08b647-3e8f-49e8-befc-9a84f8c90cd6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Already mounted: /mnt/lz2\n"
     ]
    }
   ],
   "source": [
    "def ensure_mount():\n",
    "    mnt_point = \"/mnt/lz2\"\n",
    "    mounts = [m.mountPoint for m in dbutils.fs.mounts()]\n",
    "    if mnt_point in mounts:\n",
    "        print(f\"✅ Already mounted: {mnt_point}\")\n",
    "        return\n",
    "\n",
    "    configs = {\n",
    "        \"fs.azure.account.auth.type\": \"OAuth\",\n",
    "        \"fs.azure.account.oauth.provider.type\": \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\",\n",
    "        \"fs.azure.account.oauth2.client.id\": \"b2b8369b-7480-4898-ba87-2104ce9fc28a\",         \n",
    "        \"fs.azure.account.oauth2.client.secret\": \"jCi8Q~TFDdTI-urHYBBqvXe4kXGR~2h6AviHIcr-\", \n",
    "        \"fs.azure.account.oauth2.client.endpoint\": \"https://login.microsoftonline.com/1d1656e8-380d-4ea4-947e-f4f84ba4fe61/oauth2/token\" \n",
    "    }\n",
    "\n",
    "    dbutils.fs.mount(\n",
    "        source=\"abfss://landing-zone-2@ecomadlsatul.dfs.core.windows.net\",\n",
    "        mount_point=mnt_point,\n",
    "        extra_configs=configs\n",
    "    )\n",
    "    print(f\"✅ Mounted landing-zone-2 at {mnt_point}\")\n",
    "\n",
    "ensure_mount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95923a4b-a244-46c5-ae99-4c05ef369461",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 1) Define paths \n",
    "# -----------------------------\n",
    "BASE          = \"/mnt/lz2\"\n",
    "RAW_BASE      = f\"{BASE}/to_process_data\"      \n",
    "BRONZE_BASE   = f\"{BASE}/delta/tables/bronze\"\n",
    "SILVER_BASE   = f\"{BASE}/delta/tables/silver\"\n",
    "GOLD_BASE     = f\"{BASE}/delta/tables/gold\"\n",
    "\n",
    "RAW_USERS     = f\"{RAW_BASE}/users_data\"\n",
    "RAW_BUYERS    = f\"{RAW_BASE}/buyers_data\"\n",
    "RAW_SELLERS   = f\"{RAW_BASE}/sellers_data\"\n",
    "RAW_COUNTRIES = f\"{RAW_BASE}/countries_data\"\n",
    "\n",
    "BR_USERS      = f\"{BRONZE_BASE}/users\"\n",
    "BR_BUYERS     = f\"{BRONZE_BASE}/buyers\"\n",
    "BR_SELLERS    = f\"{BRONZE_BASE}/sellers\"\n",
    "BR_COUNTRIES  = f\"{BRONZE_BASE}/countries\"\n",
    "\n",
    "SL_USERS      = f\"{SILVER_BASE}/users\"\n",
    "SL_BUYERS     = f\"{SILVER_BASE}/buyers\"\n",
    "SL_SELLERS    = f\"{SILVER_BASE}/sellers\"\n",
    "SL_COUNTRIES  = f\"{SILVER_BASE}/countries\"\n",
    "\n",
    "GOLD_OBT      = f\"{GOLD_BASE}/ecom_one_big_table\"\n",
    "\n",
    "\n",
    "dbutils.widgets.text(\"file_name\", \"\")  \n",
    "file_name = dbutils.widgets.get(\"file_name\").strip()\n",
    "SRC_USERS = f\"{RAW_USERS}/{file_name}\" if file_name else RAW_USERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b396a5bd-e33e-47e0-8357-2c141b6e13e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 2) BRONZE — read parquet from to_process_data/* and write Delta\n",
    "# ============================================================\n",
    "\n",
    "# Users (Bronze)\n",
    "userDF = (spark.read.format(\"parquet\")\n",
    "          .option(\"header\",\"true\").option(\"inferSchema\",\"true\")\n",
    "          .load(SRC_USERS))\n",
    "(userDF.write.format(\"delta\").mode(\"overwrite\").save(BR_USERS))\n",
    "\n",
    "# Buyers (Bronze)\n",
    "buyersDF = (spark.read.format(\"parquet\")\n",
    "            .option(\"header\",\"true\").option(\"inferSchema\",\"true\")\n",
    "            .load(RAW_BUYERS))\n",
    "(buyersDF.write.format(\"delta\").mode(\"overwrite\").save(BR_BUYERS))\n",
    "\n",
    "# Sellers (Bronze)\n",
    "sellersDF = (spark.read.format(\"parquet\")\n",
    "             .option(\"header\",\"true\").option(\"inferSchema\",\"true\")\n",
    "             .load(RAW_SELLERS))\n",
    "(sellersDF.write.format(\"delta\").mode(\"overwrite\").save(BR_SELLERS))\n",
    "\n",
    "# Countries (Bronze)\n",
    "countriesDF = (spark.read.format(\"parquet\")\n",
    "               .option(\"header\",\"true\").option(\"inferSchema\",\"true\")\n",
    "               .load(RAW_COUNTRIES))\n",
    "(countriesDF.write.format(\"delta\").mode(\"overwrite\").save(BR_COUNTRIES))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e347e58-0026-4b5e-8622-221fbe5505e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n|gender|\n+------+\n|Female|\n|Female|\n|  Male|\n|Female|\n|  Male|\n|Female|\n|Female|\n|Female|\n|Female|\n|  Male|\n|Female|\n|Female|\n|Female|\n|Female|\n|Female|\n|Female|\n|Female|\n|Female|\n|Female|\n|  Male|\n+------+\nonly showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3) SILVER — your original transformations (paths switched to /mnt/lz2)\n",
    "# ============================================================\n",
    "\n",
    "spark = SparkSession.builder.appName(\"EcommerceDataPipeline\").getOrCreate()\n",
    "\n",
    "# ----- Users (Silver) -----\n",
    "\n",
    "# Reading User Table\n",
    "usersDF = spark.read.format(\"delta\").load(BR_USERS)\n",
    "\n",
    "# Normalize country code to uppercase\n",
    "usersDF = usersDF.withColumn(\"countryCode\" , upper(col(\"countryCode\")))\n",
    "\n",
    "# Handling multiple languages elegently with 'expr' and 'case when'\n",
    "usersDF = usersDF.withColumn(\n",
    "    \"language_full\",\n",
    "    expr(\"CASE WHEN language = 'EN' THEN 'ENGLISH' \"\n",
    "         \"WHEN language = 'FR' THEN 'FRENCH' \"\n",
    "         \"ELSE 'Other' END \")\n",
    ")\n",
    "\n",
    "# Correcting potential data entry errors in gender column\n",
    "usersDF = usersDF.withColumn(\n",
    "    \"gender\",\n",
    "    when(col(\"gender\").startswith(\"M\"), \"Male\")\n",
    "    .when(col(\"gender\").startswith(\"F\"), \"Female\")\n",
    "    .otherwise(\"Other\")\n",
    ")\n",
    "\n",
    "# Using 'regexp_replace' to clean 'civilitytitle' values\n",
    "usersDF = usersDF.withColumn(\"civilitytitle_clean\",\n",
    "                             regexp_replace(\"civilitytitle\", \"(Mme|Ms|Mrs)\", \"Ms\"))\n",
    "\n",
    "\n",
    "#Derive new column 'Year_since_last_login' from 'daysSinceLastLogin'\n",
    "usersDF = usersDF.withColumn(\"Year_since_last_login\", col(\"daysSinceLastLogin\")/365)\n",
    "\n",
    "# calculate age of account in years and categorize into 'account_age_group'\n",
    "usersDF = usersDF.withColumn(\"account_age_years\", round(col(\"seniority\") / 365 ,2)) \\\n",
    "                 .withColumn(\"account_age_group\",\n",
    "                             when(col(\"account_age_years\") < 1 , \"New\")\n",
    "                             .when((col(\"account_age_years\") >=1) & (col(\"account_age_years\") < 3) , \"Intermediate\")\n",
    "                             .otherwise(\"Experienced\"))\n",
    "\n",
    "# Add a column with the current year for comarison \n",
    "usersDF = usersDF.withColumn(\"current_year\", year(current_date()))\n",
    "\n",
    "# Creatively combining strings to forma a unique user descriptor\n",
    "usersDF = usersDF.withColumn(\n",
    "    \"user_descriptor\",\n",
    "    concat(col(\"gender\"), lit(\"_\"),\n",
    "           col(\"countrycode\"), lit(\"_\"),\n",
    "           expr(\"substring(civilitytitle_clean,1,3)\"), lit(\"_\"),\n",
    "           col(\"language_full\"))\n",
    ")\n",
    "\n",
    "# Flag long title \n",
    "usersDF = usersDF.withColumn(\"flag_long_title\", length(col(\"civilitytitle_clean\")) > 10)\n",
    "\n",
    "# Casting\n",
    "usersDF = usersDF.withColumn(\"hasAnyApp\" , col(\"hasAnyApp\").cast(\"boolean\")) \\\n",
    "                 .withColumn(\"hasAndroidApp\" , col(\"hasAndroidApp\").cast(\"boolean\")) \\\n",
    "                 .withColumn(\"hasIosApp\" , col(\"hasIosApp\").cast(\"boolean\")) \\\n",
    "                 .withColumn(\"hasProfilePicture\" , col(\"hasProfilePicture\").cast(\"boolean\"))\n",
    "\n",
    "usersDF = usersDF.withColumn(\"socialNbFollowers\", col(\"socialNbFollowers\").cast(IntegerType())) \\\n",
    "                 .withColumn(\"socialNbFollows\" , col(\"socialNbFollows\").cast(IntegerType())) \\\n",
    "                 .withColumn(\"productsPassRate\" , col(\"productsPassRate\").cast(DecimalType(10,2))) \\\n",
    "                 .withColumn(\"seniorityAsMonths\" , col(\"seniorityAsMonths\").cast(DecimalType(10,2))) \\\n",
    "                 .withColumn(\"seniorityAsYears\" , col(\"seniorityAsYears\").cast(DecimalType(10,2)))\n",
    "\n",
    "usersDF = usersDF.withColumn(\n",
    "    \"daysSinceLastLogin\",\n",
    "    when(col(\"daysSinceLastLogin\").isNotNull(), col(\"daysSinceLastLogin\").cast(IntegerType())).otherwise(0)\n",
    ")\n",
    "\n",
    "usersDF.select(\"gender\").show()\n",
    "\n",
    "(usersDF.write.format(\"delta\").mode(\"overwrite\").save(SL_USERS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bdbf3df1-2d97-4c4d-97ff-878e2346ce6e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ----- Buyers (Silver) -----\n",
    "\n",
    "# Reading buyers table\n",
    "buyersDF = spark.read.format(\"delta\").load(BR_BUYERS)\n",
    "\n",
    "# Casting Integer Columns\n",
    "integer_columns = [\n",
    "    'buyers', 'topbuyers', 'femalebuyers', 'malebuyers',\n",
    "    'topfemalebuyers', 'topmalebuyers', 'totalproductsbought',\n",
    "    'totalproductswished', 'totalproductsliked', 'toptotalproductsbought',\n",
    "    'toptotalproductswished', 'toptotalproductsliked'\n",
    "]\n",
    "for c in integer_columns:\n",
    "    buyersDF = buyersDF.withColumn(c, col(c).cast(IntegerType()))\n",
    "\n",
    "# Casting Decimal columns\n",
    "decimal_columns = [\n",
    "    'topbuyerratio', 'femalebuyersratio', 'topfemalebuyersratio',\n",
    "    'boughtperwishlistratio', 'boughtperlikeratio', 'topboughtperwishlistratio',\n",
    "    'topboughtperlikeratio', 'meanproductsbought', 'meanproductswished',\n",
    "    'meanproductsliked', 'topmeanproductsbought', 'topmeanproductswished',\n",
    "    'topmeanproductsliked', 'meanofflinedays', 'topmeanofflinedays',\n",
    "    'meanfollowers', 'meanfollowing', 'topmeanfollowers', 'topmeanfollowing'\n",
    "]\n",
    "for c in decimal_columns:\n",
    "    buyersDF = buyersDF.withColumn(c, col(c).cast(DecimalType(10,2)))\n",
    "\n",
    "# Normalize country name \n",
    "buyersDF = buyersDF.withColumn(\"country\", initcap(col(\"country\")))\n",
    "\n",
    "for c in integer_columns:\n",
    "    buyersDF = buyersDF.fillna({c: 0})\n",
    "\n",
    "# Calculate the ratio of female to male buyers\n",
    "buyersDF = buyersDF.withColumn(\"female_to_make_ratio\",\n",
    "                               round(col(\"femalebuyers\")/(col(\"malebuyers\")+1),2))\n",
    "\n",
    "# Determine the market potential by comparing wishlist and purchases\n",
    "buyersDF = buyersDF.withColumn(\"wishlist_to_purchase_ratio\",\n",
    "                               round(col(\"totalproductswished\")/(col(\"totalproductsbought\")+1),2))\n",
    "\n",
    "# Tag countries with highes engagement ratio \n",
    "buyersDF = buyersDF.withColumn(\"high_engagement\",\n",
    "                               when(col(\"boughtperwishlistratio\") > 0.5, True).otherwise(False))\n",
    "\n",
    "# Flag market with incresing female buyers participation\n",
    "buyersDF = buyersDF.withColumn(\"growing_female_market\",\n",
    "                               when(col(\"femalebuyersratio\") > col(\"topfemalebuyersratio\"), True).otherwise(False))\n",
    "\n",
    "(buyersDF.write.format(\"delta\").mode(\"overwrite\").save(SL_BUYERS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8f237a9-af90-4557-b26d-75457679b29c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ----- Sellers (Silver) -----\n",
    "\n",
    "# Reading sellers table\n",
    "sellersDF = spark.read.format(\"delta\").load(BR_SELLERS)\n",
    "sellersDF = sellersDF \\\n",
    "    .withColumn(\"nbsellers\", col(\"nbsellers\").cast(IntegerType())) \\\n",
    "    .withColumn(\"meanproductssold\", col(\"meanproductssold\").cast(DecimalType(10, 2))) \\\n",
    "    .withColumn(\"meanproductslisted\", col(\"meanproductslisted\").cast(DecimalType(10, 2))) \\\n",
    "    .withColumn(\"meansellerpassrate\", col(\"meansellerpassrate\").cast(DecimalType(10, 2))) \\\n",
    "    .withColumn(\"totalproductssold\", col(\"totalproductssold\").cast(IntegerType())) \\\n",
    "    .withColumn(\"totalproductslisted\", col(\"totalproductslisted\").cast(IntegerType())) \\\n",
    "    .withColumn(\"meanproductsbought\", col(\"meanproductsbought\").cast(DecimalType(10, 2))) \\\n",
    "    .withColumn(\"meanproductswished\", col(\"meanproductswished\").cast(DecimalType(10, 2))) \\\n",
    "    .withColumn(\"meanproductsliked\", col(\"meanproductsliked\").cast(DecimalType(10, 2))) \\\n",
    "    .withColumn(\"totalbought\", col(\"totalbought\").cast(IntegerType())) \\\n",
    "    .withColumn(\"totalwished\", col(\"totalwished\").cast(IntegerType())) \\\n",
    "    .withColumn(\"totalproductsliked\", col(\"totalproductsliked\").cast(IntegerType())) \\\n",
    "    .withColumn(\"meanfollowers\", col(\"meanfollowers\").cast(DecimalType(10, 2))) \\\n",
    "    .withColumn(\"meanfollows\", col(\"meanfollows\").cast(DecimalType(10, 2))) \\\n",
    "    .withColumn(\"percentofappusers\", col(\"percentofappusers\").cast(DecimalType(10, 2))) \\\n",
    "    .withColumn(\"percentofiosusers\", col(\"percentofiosusers\").cast(DecimalType(10, 2))) \\\n",
    "    .withColumn(\"meanseniority\", col(\"meanseniority\").cast(DecimalType(10, 2)))\n",
    "\n",
    "# Normalize country name and gender value \n",
    "sellersDF = sellersDF.withColumn(\"country\", initcap(col(\"country\"))) \\\n",
    "                     .withColumn(\"sex\"    , initcap(col(\"sex\")))\n",
    "\n",
    "# Add a column to categorize the number of sellers\n",
    "sellersDF = sellersDF.withColumn(\n",
    "    \"seller_size_category\",\n",
    "    when(col(\"nbsellers\") < 500, \"Small\")\n",
    "    .when((col(\"nbsellers\") >= 500) & (col(\"nbsellers\") < 2000), \"Medium\")\n",
    "    .otherwise(\"Large\")\n",
    ")\n",
    "\n",
    "# Calculate the mean product listed per seller as an indicator of seller activity\n",
    "sellersDF = sellersDF.withColumn(\n",
    "    \"mean_product_listed_per_seller\",\n",
    "    round(col(\"totalproductslisted\") / col(\"nbsellers\"), 2)\n",
    ")\n",
    "\n",
    "# Indentify markets with high seller pass rate\n",
    "sellersDF = sellersDF.withColumn(\n",
    "    \"high_seller_pass_rate\",\n",
    "    when(col(\"meansellerpassrate\") > 0.75, \"High\").otherwise(\"Normal\")\n",
    ")\n",
    "\n",
    "mean_pass_rate = sellersDF.select(round(avg(\"meansellerpassrate\"),2).alias(\"avg_pass_rate\")) \\\n",
    "                          .collect()[0][\"avg_pass_rate\"]\n",
    "\n",
    "sellersDF = sellersDF.withColumn(\n",
    "    \"meansellerpassrate\",\n",
    "    when(col(\"meansellerpassrate\").isNull(), mean_pass_rate).otherwise(col(\"meansellerpassrate\"))\n",
    ")\n",
    "\n",
    "(sellersDF.write.format(\"delta\").mode(\"overwrite\").save(SL_SELLERS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd5e0ee0-e800-45cd-b262-1113332aef27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ----- Countries (Silver) -----\n",
    "\n",
    "# Reading from countries table\n",
    "countriesDF = spark.read.format(\"delta\").load(BR_COUNTRIES)\n",
    "countriesDF = countriesDF \\\n",
    "    .withColumn(\"sellers\", col(\"sellers\").cast(IntegerType())) \\\n",
    "    .withColumn(\"topsellers\", col(\"topsellers\").cast(IntegerType())) \\\n",
    "    .withColumn(\"topsellerratio\", col(\"topsellerratio\").cast(DecimalType(10, 2))) \\\n",
    "    .withColumn(\"femalesellersratio\", col(\"femalesellersratio\").cast(DecimalType(10, 2))) \\\n",
    "    .withColumn(\"topfemalesellersratio\", col(\"topfemalesellersratio\").cast(DecimalType(10, 2))) \\\n",
    "    .withColumn(\"femalesellers\", col(\"femalesellers\").cast(IntegerType())) \\\n",
    "    .withColumn(\"malesellers\", col(\"malesellers\").cast(IntegerType())) \\\n",
    "    .withColumn(\"topfemalesellers\", col(\"topfemalesellers\").cast(IntegerType())) \\\n",
    "    .withColumn(\"topmalesellers\", col(\"topmalesellers\").cast(IntegerType())) \\\n",
    "    .withColumn(\"countrysoldratio\", col(\"countrysoldratio\").cast(DecimalType(10, 2))) \\\n",
    "    .withColumn(\"bestsoldratio\", col(\"bestsoldratio\").cast(DecimalType(10, 2))) \\\n",
    "    .withColumn(\"toptotalproductssold\", col(\"toptotalproductssold\").cast(IntegerType())) \\\n",
    "    .withColumn(\"totalproductssold\", col(\"totalproductssold\").cast(IntegerType())) \\\n",
    "    .withColumn(\"toptotalproductslisted\", col(\"toptotalproductslisted\").cast(IntegerType())) \\\n",
    "    .withColumn(\"totalproductslisted\", col(\"totalproductslisted\").cast(IntegerType())) \\\n",
    "    .withColumn(\"topmeanproductssold\", col(\"topmeanproductssold\").cast(DecimalType(10, 2))) \\\n",
    "    .withColumn(\"topmeanproductslisted\", col(\"topmeanproductslisted\").cast(DecimalType(10, 2))) \\\n",
    "    .withColumn(\"meanproductssold\", col(\"meanproductssold\").cast(DecimalType(10, 2))) \\\n",
    "    .withColumn(\"meanproductslisted\", col(\"meanproductslisted\").cast(DecimalType(10, 2))) \\\n",
    "    .withColumn(\"meanofflinedays\", col(\"meanofflinedays\").cast(DecimalType(10, 2))) \\\n",
    "    .withColumn(\"topmeanofflinedays\", col(\"topmeanofflinedays\").cast(DecimalType(10, 2))) \\\n",
    "    .withColumn(\"meanfollowers\", col(\"meanfollowers\").cast(DecimalType(10, 2))) \\\n",
    "    .withColumn(\"meanfollowing\", col(\"meanfollowing\").cast(DecimalType(10, 2))) \\\n",
    "    .withColumn(\"topmeanfollowers\", col(\"topmeanfollowers\").cast(DecimalType(10, 2))) \\\n",
    "    .withColumn(\"topmeanfollowing\", col(\"topmeanfollowing\").cast(DecimalType(10, 2)))\n",
    "\n",
    "# Transformation\n",
    "countriesDF = countriesDF.withColumn(\"country\", initcap(col(\"country\")))\n",
    "\n",
    "# Calculating the ratio of top sellers to total sellers\n",
    "countriesDF = countriesDF.withColumn(\"top_seller_ratio\", \n",
    "                                     round(col(\"topsellers\") / col(\"sellers\"), 2))\n",
    "\n",
    "# countriesDF countries with high ratio of female sellers \n",
    "countriesDF = countriesDF.withColumn(\"high_female_seller_ratio\",\n",
    "                                     when(col(\"femalesellersratio\") > 0.5, True).otherwise(False))\n",
    "\n",
    "# Adding a performance indicator based on the sold/listed ratio\n",
    "countriesDF = countriesDF.withColumn(\"performane_indicator\",\n",
    "                                     round(col(\"toptotalproductssold\") / (col(\"toptotalproductslisted\") + 1), 2))\n",
    "\n",
    "#Flag countries with exceptionally high performance \n",
    "countriesDF = countriesDF.withColumn(\"high_performance\",\n",
    "                                     when(col(\"performane_indicator\") > 0.8, \"True\").otherwise(\"False\"))\n",
    "\n",
    "countriesDF = countriesDF.withColumn(\n",
    "    \"activity_level\",\n",
    "    when(col(\"meanofflinedays\") < 30, \"Higly Active\")\n",
    "    .when((col(\"meanofflinedays\") >= 30) & (col(\"meanofflinedays\") < 60), \"Moderately Active\")\n",
    "    .otherwise(\"Low Activity\")\n",
    ")\n",
    "\n",
    "(countriesDF.write.format(\"delta\").mode(\"overwrite\").save(SL_COUNTRIES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8312c865-d46f-44cf-afd3-fe320b315a49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+--------------------+-----------------------+-----------------------+---------------+-----------------------+---------------------+-----------------+--------------------+-----------------------+---------------------+--------------------------+------------------------+------------+----------+-------------+-----------+----------------+--------------+-------------+-----------+------------------------+--------------------------+\n|Country|Users_productsSold|Users_productsWished|Users_account_age_years|Users_account_age_group|Users_hasanyapp|Users_socialnbfollowers|Users_flag_long_title|Countries_Sellers|Countries_TopSellers|Countries_FemaleSellers|Countries_MaleSellers|Countries_TopFemaleSellers|Countries_TopMaleSellers|Buyers_Total|Buyers_Top|Buyers_Female|Buyers_Male|Buyers_TopFemale|Buyers_TopMale|Sellers_Total|Sellers_Sex|Sellers_MeanProductsSold|Sellers_MeanProductsListed|\n+-------+------------------+--------------------+-----------------------+-----------------------+---------------+-----------------------+---------------------+-----------------+--------------------+-----------------------+---------------------+--------------------------+------------------------+------------+----------+-------------+-----------+----------------+--------------+-------------+-----------+------------------------+--------------------------+\n|   Inde|                 0|                   0|                   8.78|            Experienced|          false|                      3|                false|             NULL|                NULL|                   NULL|                 NULL|                      NULL|                    NULL|        NULL|      NULL|         NULL|       NULL|            NULL|          NULL|         NULL|       NULL|                    NULL|                      NULL|\n|   Inde|                 0|                   0|                   8.78|            Experienced|          false|                      3|                false|             NULL|                NULL|                   NULL|                 NULL|                      NULL|                    NULL|        NULL|      NULL|         NULL|       NULL|            NULL|          NULL|         NULL|       NULL|                    NULL|                      NULL|\n|   Inde|                 0|                   0|                   8.78|            Experienced|           true|                      3|                false|             NULL|                NULL|                   NULL|                 NULL|                      NULL|                    NULL|        NULL|      NULL|         NULL|       NULL|            NULL|          NULL|         NULL|       NULL|                    NULL|                      NULL|\n|   Inde|                 0|                   0|                   8.78|            Experienced|          false|                      3|                false|             NULL|                NULL|                   NULL|                 NULL|                      NULL|                    NULL|        NULL|      NULL|         NULL|       NULL|            NULL|          NULL|         NULL|       NULL|                    NULL|                      NULL|\n|   Inde|                 0|                   0|                   8.78|            Experienced|          false|                      3|                false|             NULL|                NULL|                   NULL|                 NULL|                      NULL|                    NULL|        NULL|      NULL|         NULL|       NULL|            NULL|          NULL|         NULL|       NULL|                    NULL|                      NULL|\n|   Inde|                 0|                   9|                   8.78|            Experienced|           true|                      3|                false|             NULL|                NULL|                   NULL|                 NULL|                      NULL|                    NULL|        NULL|      NULL|         NULL|       NULL|            NULL|          NULL|         NULL|       NULL|                    NULL|                      NULL|\n|   Inde|                 0|                   0|                   8.78|            Experienced|           true|                      3|                false|             NULL|                NULL|                   NULL|                 NULL|                      NULL|                    NULL|        NULL|      NULL|         NULL|       NULL|            NULL|          NULL|         NULL|       NULL|                    NULL|                      NULL|\n|   Inde|                 0|                   0|                   8.78|            Experienced|          false|                      3|                false|             NULL|                NULL|                   NULL|                 NULL|                      NULL|                    NULL|        NULL|      NULL|         NULL|       NULL|            NULL|          NULL|         NULL|       NULL|                    NULL|                      NULL|\n|   Inde|                 0|                   0|                   8.78|            Experienced|           true|                      3|                false|             NULL|                NULL|                   NULL|                 NULL|                      NULL|                    NULL|        NULL|      NULL|         NULL|       NULL|            NULL|          NULL|         NULL|       NULL|                    NULL|                      NULL|\n|   Inde|                 0|                   0|                   8.78|            Experienced|           true|                      3|                false|             NULL|                NULL|                   NULL|                 NULL|                      NULL|                    NULL|        NULL|      NULL|         NULL|       NULL|            NULL|          NULL|         NULL|       NULL|                    NULL|                      NULL|\n|   Inde|                 0|                   0|                   8.77|            Experienced|          false|                      3|                false|             NULL|                NULL|                   NULL|                 NULL|                      NULL|                    NULL|        NULL|      NULL|         NULL|       NULL|            NULL|          NULL|         NULL|       NULL|                    NULL|                      NULL|\n|   Inde|                 0|                   0|                   8.77|            Experienced|          false|                      3|                false|             NULL|                NULL|                   NULL|                 NULL|                      NULL|                    NULL|        NULL|      NULL|         NULL|       NULL|            NULL|          NULL|         NULL|       NULL|                    NULL|                      NULL|\n|   Inde|                 0|                   0|                   8.77|            Experienced|           true|                      3|                false|             NULL|                NULL|                   NULL|                 NULL|                      NULL|                    NULL|        NULL|      NULL|         NULL|       NULL|            NULL|          NULL|         NULL|       NULL|                    NULL|                      NULL|\n|   Inde|                 0|                   0|                   8.77|            Experienced|           true|                      3|                false|             NULL|                NULL|                   NULL|                 NULL|                      NULL|                    NULL|        NULL|      NULL|         NULL|       NULL|            NULL|          NULL|         NULL|       NULL|                    NULL|                      NULL|\n|   Inde|                 0|                   0|                   8.77|            Experienced|           true|                      3|                false|             NULL|                NULL|                   NULL|                 NULL|                      NULL|                    NULL|        NULL|      NULL|         NULL|       NULL|            NULL|          NULL|         NULL|       NULL|                    NULL|                      NULL|\n|   Inde|                 0|                   0|                   8.77|            Experienced|           true|                      3|                false|             NULL|                NULL|                   NULL|                 NULL|                      NULL|                    NULL|        NULL|      NULL|         NULL|       NULL|            NULL|          NULL|         NULL|       NULL|                    NULL|                      NULL|\n|   Inde|                 0|                   0|                   8.77|            Experienced|           true|                      3|                false|             NULL|                NULL|                   NULL|                 NULL|                      NULL|                    NULL|        NULL|      NULL|         NULL|       NULL|            NULL|          NULL|         NULL|       NULL|                    NULL|                      NULL|\n|   Inde|                 0|                   0|                   8.77|            Experienced|          false|                      3|                false|             NULL|                NULL|                   NULL|                 NULL|                      NULL|                    NULL|        NULL|      NULL|         NULL|       NULL|            NULL|          NULL|         NULL|       NULL|                    NULL|                      NULL|\n|   Inde|                 0|                   0|                   8.77|            Experienced|          false|                      3|                false|             NULL|                NULL|                   NULL|                 NULL|                      NULL|                    NULL|        NULL|      NULL|         NULL|       NULL|            NULL|          NULL|         NULL|       NULL|                    NULL|                      NULL|\n|   Inde|                 0|                   0|                   8.77|            Experienced|          false|                      3|                false|             NULL|                NULL|                   NULL|                 NULL|                      NULL|                    NULL|        NULL|      NULL|         NULL|       NULL|            NULL|          NULL|         NULL|       NULL|                    NULL|                      NULL|\n+-------+------------------+--------------------+-----------------------+-----------------------+---------------+-----------------------+---------------------+-----------------+--------------------+-----------------------+---------------------+--------------------------+------------------------+------------+----------+-------------+-----------+----------------+--------------+-------------+-----------+------------------------+--------------------------+\nonly showing top 20 rows\n Pipeline finished: Bronze → Silver → Gold\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 4) GOLD — your original join to One Big Table\n",
    "# ============================================================\n",
    "\n",
    "spark = SparkSession.builder.appName(\"GoldLayerCreation\").getOrCreate()\n",
    "\n",
    "# reading the silver delta tables \n",
    "silver_sellers   = spark.read.format(\"delta\").load(SL_SELLERS)\n",
    "silver_buyers    = spark.read.format(\"delta\").load(SL_BUYERS)\n",
    "silver_users     = spark.read.format(\"delta\").load(SL_USERS)\n",
    "silver_countries = spark.read.format(\"delta\").load(SL_COUNTRIES)\n",
    "\n",
    "# Perform the join operations\n",
    "comprehensive_user_table = silver_users \\\n",
    "    .join(silver_countries, [\"country\"], \"outer\") \\\n",
    "    .join(silver_buyers,    [\"country\"], \"outer\") \\\n",
    "    .join(silver_sellers,   [\"country\"], \"outer\")\n",
    "\n",
    "# Select and alias columns from each dataframe to ensure uniqueness\n",
    "comprehensive_user_table = comprehensive_user_table.select(\n",
    "    silver_users[\"country\"].alias(\"Country\"),\n",
    "    # From silver_users\n",
    "    silver_users[\"productsSold\"].alias(\"Users_productsSold\"),\n",
    "    silver_users[\"productsWished\"].alias(\"Users_productsWished\"),\n",
    "    silver_users[\"account_age_years\"].alias(\"Users_account_age_years\"),\n",
    "    silver_users[\"account_age_group\"].alias(\"Users_account_age_group\"),\n",
    "    silver_users[\"hasanyapp\"].alias(\"Users_hasanyapp\"),\n",
    "    silver_users[\"socialnbfollowers\"].alias(\"Users_socialnbfollowers\"),\n",
    "    silver_users[\"flag_long_title\"].alias(\"Users_flag_long_title\"),\n",
    "    # From silver_countries\n",
    "    silver_countries[\"sellers\"].alias(\"Countries_Sellers\"),\n",
    "    silver_countries[\"topsellers\"].alias(\"Countries_TopSellers\"),\n",
    "    silver_countries[\"femalesellers\"].alias(\"Countries_FemaleSellers\"),\n",
    "    silver_countries[\"malesellers\"].alias(\"Countries_MaleSellers\"),\n",
    "    silver_countries[\"topfemalesellers\"].alias(\"Countries_TopFemaleSellers\"),\n",
    "    silver_countries[\"topmalesellers\"].alias(\"Countries_TopMaleSellers\"),\n",
    "    # From silver_buyers\n",
    "    silver_buyers[\"buyers\"].alias(\"Buyers_Total\"),\n",
    "    silver_buyers[\"topbuyers\"].alias(\"Buyers_Top\"),\n",
    "    silver_buyers[\"femalebuyers\"].alias(\"Buyers_Female\"),\n",
    "    silver_buyers[\"malebuyers\"].alias(\"Buyers_Male\"),\n",
    "    silver_buyers[\"topfemalebuyers\"].alias(\"Buyers_TopFemale\"),\n",
    "    silver_buyers[\"topmalebuyers\"].alias(\"Buyers_TopMale\"),\n",
    "    # From silver_sellers\n",
    "    silver_sellers[\"nbsellers\"].alias(\"Sellers_Total\"),\n",
    "    silver_sellers[\"sex\"].alias(\"Sellers_Sex\"),\n",
    "    silver_sellers[\"meanproductssold\"].alias(\"Sellers_MeanProductsSold\"),\n",
    "    silver_sellers[\"meanproductslisted\"].alias(\"Sellers_MeanProductsListed\"),\n",
    ")\n",
    "\n",
    "comprehensive_user_table.show()\n",
    "(comprehensive_user_table.write.format(\"delta\").mode(\"overwrite\").save(GOLD_OBT))\n",
    "\n",
    "print(\" Pipeline finished: Bronze → Silver → Gold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1307040a-c792-4065-8b27-f5bed6f40718",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Moved users_data: 1 files -> /mnt/lz2/processed_data/users_data/load_ts=20250811_215706/\n Moved buyers_data: 1 files -> /mnt/lz2/processed_data/buyers_data/load_ts=20250811_215706/\n Moved sellers_data: 1 files -> /mnt/lz2/processed_data/sellers_data/load_ts=20250811_215706/\n Moved countries_data: 1 files -> /mnt/lz2/processed_data/countries_data/load_ts=20250811_215706/\n"
     ]
    }
   ],
   "source": [
    "ts = datetime.now(timezone.utc).strftime(\"%Y%m%d_%H%M%S\")\n",
    "entities = [\"users_data\", \"buyers_data\", \"sellers_data\", \"countries_data\"]\n",
    "\n",
    "for e in entities:\n",
    "    src = f\"/mnt/lz2/to_process_data/{e}\"\n",
    "    dst = f\"/mnt/lz2/processed_data/{e}/load_ts={ts}/\"\n",
    "    try:\n",
    "        # any parquet files to move?\n",
    "        files = [f for f in dbutils.fs.ls(src) if f.path.lower().endswith(\".parquet\")]\n",
    "        if not files:\n",
    "            print(f\" No new files for {e}\")\n",
    "            continue\n",
    "\n",
    "        dbutils.fs.mkdirs(dst)\n",
    "        # move everything inside src into dst (fast & simple)\n",
    "        dbutils.fs.mv(src, dst, True)\n",
    "        # recreate empty source folder for next run\n",
    "        dbutils.fs.mkdirs(src)\n",
    "        print(f\" Moved {e}: {len(files)} files -> {dst}\")\n",
    "    except Exception as ex:\n",
    "        print(f\" Skipped {e}: {ex}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9a48d77c-6e20-47a7-a0f6-d8579f3f58a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Transformation medeliion structure",
   "widgets": {
    "file_name": {
     "currentValue": "",
     "nuid": "df7b4764-dc82-47d5-a37e-d4027b20fc3d",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "file_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "file_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}