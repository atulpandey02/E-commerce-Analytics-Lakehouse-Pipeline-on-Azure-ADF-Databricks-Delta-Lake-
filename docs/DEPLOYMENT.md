# ğŸ“„ Project Documentation â€“ E-Commerce Analytics Lakehouse Pipeline

This `docs` directory contains detailed documentation for the **E-Commerce Analytics Lakehouse Pipeline** project, including architecture details, setup instructions, workflow explanations, and references for future development.

---

## ğŸ“‚ Documentation Structure

| File / Folder | Description |
|---------------|-------------|
| **architecture.md** | Detailed explanation of the system architecture with diagrams. |
| **workflow.md** | Step-by-step breakdown of the pipeline workflow from ingestion to analytics. |
| **setup_guide.md** | Instructions for setting up the project locally and on Azure. |
| **adf_pipeline_exports/** | JSON exports of Azure Data Factory pipelines. |
| **databricks_notebooks/** | Additional Databricks notebooks used in transformations or analytics. |
| **queries/** | Example SQL queries used for dashboards and analytics. |

---

## ğŸ”¹ Overview

The **E-Commerce Analytics Lakehouse Pipeline** processes and analyzes e-commerce datasets using:
- **Azure Data Factory (ADF)** for ingestion & orchestration.
- **ADLS Gen2** for data storage.
- **Databricks (Apache Spark)** for transformation using the **Medallion Architecture**.
- **Delta Lake** for optimized analytics storage.
- **Databricks SQL Dashboards** for visualization.

---

## ğŸ”¹ Architecture Summary

- **Bronze Layer** â†’ Raw data ingestion.
- **Silver Layer** â†’ Data cleaning, validation, and integration.
- **Gold Layer** â†’ Aggregated, business-ready datasets.

Refer to [`architecture.md`](architecture.md) for a full diagram and explanation.

---

## ğŸ”¹ Workflow Summary

1. **Ingestion** â€“ Data Factory ingests raw CSV/JSON files from `data.world`.
2. **Processing** â€“ Databricks processes raw files through Bronze â†’ Silver â†’ Gold.
3. **Storage** â€“ Delta tables stored in ADLS Gen2.
4. **Analytics** â€“ Dashboards built in Databricks SQL.

---

## ğŸ“Œ Additional Resources

- **[Azure Data Factory Documentation](https://learn.microsoft.com/azure/data-factory/)**
- **[Azure Databricks Documentation](https://learn.microsoft.com/azure/databricks/)**
- **[Delta Lake Documentation](https://delta.io/documentation/)**

---

## ğŸ›  Future Enhancements
- Implement CI/CD for pipeline deployment.
- Add real-time streaming ingestion using Azure Event Hubs.
- Deploy dashboards via Power BI for wider accessibility.

---

# ğŸ— Architecture â€“ E-Commerce Analytics Lakehouse Pipeline

## ğŸ”¹ Overview
The architecture follows the **Medallion Architecture** pattern:  
**Bronze â†’ Silver â†’ Gold** layers for structured data processing and analytics.

---

## ğŸ”¹ Components

1. **Azure Data Factory (ADF)** â€“ Orchestrates ingestion from `data.world` into Azure Data Lake Storage Gen2.
2. **ADLS Gen2** â€“ Stores all raw, intermediate, and curated datasets.
3. **Databricks (Apache Spark)** â€“ Processes data across Bronze, Silver, and Gold stages.
4. **Delta Lake** â€“ Stores Gold layer tables with ACID compliance and time travel.
5. **Databricks SQL Dashboards** â€“ Provides business analytics and KPIs.

---

## ğŸ”¹ Data Flow

```plaintext
Data Source (data.world) 
       â†“
Azure Data Factory (ADF) â†’ ADLS Gen2 (Bronze Layer: Raw Data)
       â†“
Databricks (Bronze â†’ Silver â†’ Gold)
       â†“
Delta Lake (Gold Tables)
       â†“
Databricks SQL Dashboard

